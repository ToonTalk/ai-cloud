<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Speech Output - AI Teacher's Guide</title>
<link href="ai-teacher-guide.css" rel="stylesheet">
<link rel="icon" type="image/png" href="images/eCraft2Learn-Favicon.png" />
</head><body>
<h2>A teacher's guide to helping students build AI apps and artefacts</h2>
<h3>Chapter 1 - Speech Output</h3>
<h4>Ken Kahn, University of Oxford</h4>
<h3>Introduction</h3>
<p>The importance of artificial Intelligence in society, the work place, and the economy is rapidly increasing.
It is becoming an important part of many other technologies. AI conversational agents are becoming common in phones and PCs (Siri, Cortana, OK Google).
Driverless vehicles are coming soon.
Finance, medicine, and many other fields are relying more and more on AI.
Even toys are beginning to embed AI.</p>

<p>Is there something to learn about intelligence in general by studying AI?
AI researchers attempts to give computers the abilities to perceive, to solve problems, to plan, and to reason
shed light on intelligence beyond what studying human and animal psychology can.</p>

<p>AI raises many questions:</p>
<ul><li>What is the future of work?</li>
<li>How dangerous is AI?</li>
<li>How to ensure AIs make ethical choices?</li>
<li>Would you want a robot to be your child's best friend?</li></ul>
<h3>Ways of teaching AI</h3>
<p>Broadly there are three approaches</p>
<ol><li>Readings, lectures, and discussions about AI's history, ideas, and technologies</li>
<li>Readings, lectures, and discussions about social issues impacted by AI</li>
<li>Supporting hands-on experiences creating AI apps and artefacts</li></ol>

<p>While this guide touches on 1 and 2 and its focus is on 3.
While some aspects of building AI applications are best suited for those with phds in the field,
there are many projects that even young school students can do.
If the power of speech and image recognition or the possibilities of machine learning are given easy programming interfaces
then even beginners can use them in their creations.</p>
<h3>Speech output</h3>
<p>Let's start by exploring speech synthesis.
Is the ability to transform text into spoken speech really an example of AI?
Humans need to spend a long time learning to read (out loud).
But reading involves character recognition and spelling as well as comprehension.
When a computer produces speech none of that is involved.
Is this an aspect of intelligent behaviour or it is just like a parrot speaking?
Perhaps a good topic for students to discuss.
And note that <a href="https://en.wikipedia.org/wiki/Alex_(parrot)" target="_blank">Alex the parrot</a> clearly did more than "parroting" speech.</p>

<p>Before discussing what is technically involved in synthesising speech let's look at how it can be used by students.
Let's start with the simplest program block for speaking. Click on it to try it out.
(Currently these blocks only work well in Chrome.
The first time one is used it fetches voices over the network and that may take several seconds.)</p>

<div class="iframe-container"> 
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/simple speak block.xml">
</iframe></div>

<h4>How does this work?</h4>
<p>Modern speech synthesizers (also called "text-to-speech engines" or "TTS engines") start by preprocessing the text.
Numbers, abbreviations, dates, and special characters are turned into words.
For example, "42" becomes "forty two" (assuming the language is set to English).
Next words are turned into <a href="https://en.wikipedia.org/wiki/Phoneme" target="_blank">phonemes</a>.
A phoneme is the unit of sound that words are made of.
A phoneme is described phonetically so later stages can pronounce the words.
For example, 
<span
style='font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;
widows: 2;-webkit-text-stroke-width: 0px;text-decoration-style: initial;
text-decoration-color: initial;float:none;word-spacing:0px'>/</span>&#712;f&#601;&#650;ni&#720;m</span><span
style='font-variant-ligatures: normal;font-variant-caps: normal;orphans: 2;
widows: 2;-webkit-text-stroke-width: 0px;text-decoration-style: initial;
text-decoration-color: initial;float:none;word-spacing:0px'>/</span></span>
is how the word "phoneme" is pronounced.
This can be done by a dictionary look up or by using pronunciation rules.
Finally sounds are generated as a sequence of pitch and volume changes (typically many thousands per second).
There are three approaches to doing this last step:
<i>concatenative</i> where recorded bits of speech are "glued" together,
<i>formant</i> where each phoneme is synthesized,
and <i>articulatory</i> where human tongues and vocal chords are simulated.</p>

<p>More details about how speech synthesis works can be found in the <b>Additional resources</b> section at the bottom of this page.</p>

<h4>Sentences are more than a series of words</h4>
</p>Speech synthesizers do more than just say each word in a sentence.
They attempt to produce a natural prosody.
And they speak questions differently from sentences.
</p>

<div  class="iframe-container" style="width: 580px; height: 140px"> 
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/separate words.xml"> 
</iframe></div>

<p>And for a human speaking numbers and punctuation signs can be a bit challenging.
Is this a sign of intelligence?</p>

<div class="iframe-container"> 
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/numbers signs.xml"> 
</iframe></div>

<h4>Problems combining speech and sound effects</h4>
<p>Suppose one wanted the computer to speech, be interrupted by a door bell, and respond accordingly.
Try clicking this and you'll hear there is a problem:</p>

<div  class="iframe-container" style="width: 480px; height: 140px"> 
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/doorbell problem.xml">
</iframe></div>

<p>The problem is because the way the speak block works is that it tells the browser to begin speaking and then continues with the next action.
What we want is to have the door bell sound played <i>after</i> the first utterance is finished.
For this we need a slightly more complex block that accepts actions to do after speaking:</p>

<div class="iframe-container" style="width: 600px; height: 140px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/doorbell fix.xml">
</iframe></div>

<h4>What is speech synthesis good for?</h4>
<p>Speech synthesis is a good way for software to communicate with people that are blind or visually impaired.
And for devices such as a talking clock or a robot without a display there are few alternatives.
Or when the user's eyes need to attend to something exclusively (e.g. a surgeon during an operation or a pilot flying a plane).
Speech output is often the best way to communicate with children or adults who have yet to learn to read.
And speech synthesis gives those who physically cannot speak (e.g. Stephen Hawking) a way to communicate.
Many argue that a conversation is often a more natural, friendly, and more pleasant interface to devices
than displays, keyboards, mice, buttons, and touch sensors.</p>

<h4>Controlling speech output</h4>
<p>A person can speak slow or fast, in a low or high pitch, quietly or loudly, and more.
And different people have different voices and accents.
To mirror these abilities a more complex block is available.
A parameter value of 1 means the normal pitch, rate, or volume.
Note that depending upon the voice and browser some of these parameters are ignored.</p>

<div class="iframe-container" style="width: 800px; height: 100px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/rate pitch volume.xml">
</iframe></div>

<p>Regarding the 'language' option, unfortunately many browsers currently ignore it.
The argument should be one of the <a href="https://en.wikipedia.org/wiki/IETF_language_tag" target="_blank">IETF language tags</a>.</p>

<p>Fortunately in some browsers (e.g. Chrome) some voices are associated with a language.
When a non-English voice is given English to speak it typically speaks it with an accent.
The selection of voices available depends upon the browser and the operating system.
Click 'get voices' to see the list of voices and use the voice number in the speak command.</p>

<div class="iframe-container" style="width: 800px; height: 600px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/voices.xml"> 
</iframe></div>

<p>A voice is more than just a voice.
Listen to the two ways of reading dates.</p>

<div class="iframe-container" style="width: 800px; height: 200px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/dates.xml"> 
</iframe></div>

<h4>If your browser has too few available voices or you want to try a different speech engine</h4>
<p>Some browsers and some operating systems have very few (or <i>no</i>) voices.
An alternative speech block uses <a href="http://mary.dfki.de/" target="_blank">a server in Germany</a> that has its own set of voices.</p>

<div class="iframe-container" style="width: 800px; height: 500px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/Mary voices.xml"> 
</iframe></div>

<h4>Heteronyms cause problems</h4>
<p><a href="https://en.wikipedia.org/wiki/Heteronym_(linguistics)" target="_blank">Heteronyms</a> are words that mean and sound different but are spelled the same.
"Read" can sound like "reed" or "red" depending upon the tense.
"Lead" the verb sounds different from "lead" the metal.
Some voices are better than others at using the correct pronounciation.
Explore how different voices deal with "read" in the following.
And edit the sentences to see how they deal with "lead" and other words.</p>

<div class="iframe-container" style="width: 800px; height: 400px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="../snap/snap.html"
        project_path="../AI-teacher-guide-projects/read problem.xml"> 
</iframe></div>

<h4>Two sample programs using speech synthesis</h4>
<p>This <a href="https://snap.berkeley.edu/snapsource/snap.html#present:Username=toontalk&ProjectName=speak%20randomly" target="_blank">
sample speech output program</a> uses random settings for rate, pitch, and voice.
When one clicks on the numbers a random number is spoken with a random voice (and hence a random language) as well as a random pitch and rate.
Numbers are well-suited for this since numbers are spoken in the language of the voice.
The parrot repeats what it hears (see <a href="chapter-2.html">the next chapter</a>).
Hearing your utterances repeated in a strange voice with a random pitch and rate can be entertaining.
As can hearing your speech repeated in a foreign accent.
As with all sample programs the blocks implementing it can be easily found.
Here the sprites 'Parrot' and 'Numbers' contain the sample programs.</p>

<h4>Possible project ideas using speech output</h4>
<p>Here are some ideas for projects using only speech output, see <a href="chapter-2.html">the next chapter</a>
for ideas combining speech input and output.
<ul>
<li>Have sprites put on a play where each sprite speaks with a different voice.</li>
<li>Have a robot talk out loud as it moves around. E.g. "whoops" when it collides with something, or "time to turn" before it turns.</li>
<li>Make a page reader that speaks the contents of a file on the web.</li>
<li>Program explanation or debugging by having the program speak as it executes.</li>
<li>Make a talking clock or calculator.</li>
<li>There are thousands more ways students could use speech output in their projects.</li>
</ul></p>

<h4>Is there even more to speech synthesis?</h4>
<p>There are many more possibilities to control speech.
A voice can sound like a robot, like whispering, like a crowd in a stadium or a chorus.
You can experiment with these kinds of speech effects at <a href="http://mary.dfki.de:59125/" target="_blank">the MARY TTS site</a>
by clicking on the 'Show Audio Effects' button.</p>

<p>Speech can be emotional; the speaker can sound angry, happy, sad, and so on.
One way to experiment with this is to change the input type from 'TEXT' to 'EMOTIONML' at  <a href="http://mary.dfki.de:59125/" target="_blank">the MARY TTS site</a>.
There is a standard called <a href="https://www.w3.org/TR/speech-synthesis/" target="_blank">Speech Synthesis Markup Language</a>
that provides great control over how the speech is generated.
However, it has yet to be implemented in the voices one commonly finds available in browsers.</p>

<p>A very impressive use of controlled speech is the <a href="https://experiments.withgoogle.com/ai/giorgio-cam" target="_blank">Giorgio Cam</a>
experiment by Google researchers.
It combines computer vision and controlled speech to rap about what is in front of a web cam.</p>

<h3>Where to get these blocks to use in projects</h3>
<p>All of these speech output blocks as well other AI blocks are available to use in <a href="https://snap.berkeley.edu/" target="_blank">Snap!</a> in
this <a href="https://snap.berkeley.edu/snapsource/snap.html#present:Username=toontalk&ProjectName=eCraft2Learn" target="_blank">Snap project</a>.
They can also be used together with blocks for controlling Arduinos by downloading and then importing
<a href="https://toontalk.github.io/ai-cloud/AI-Teacher-Guide/eCraft2Learn%20S4A.xml" download>this file</a>
into <a href="http://snap4arduino.rocks/" target="_blank">Snap4Arduino</a>.

<h3>Additional resouces</h3>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition" target="_blank">A complete description of the speech synthesis API</a>
that web browsers support.</p>

<p><a href="http://research.spa.aalto.fi/publications/theses/lemmetty_mst/chap2.html" target="_blank">A history of speech synthesis</a>.</p>

<p><i>Explain that Stuff</i> has <a href="http://www.explainthatstuff.com/how-speech-synthesis-works.html" target="_blank">
a long explanation including a history of speech synthesis</a>.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Speech_synthesis" target="_blank">Wikipedia's entry</a> is good.</p>

<h3>Learn about speech input</h3>
<a href="chapter-2.html">Go to the next chapter on speech recognition</a>.

<h3>Acknowledgements</h3>
<p>This research was supported by the <a href="https://project.ecraft2learn.eu/" target="_blank">eCraft2Learn project</a>
funded by the European Union's Horizon 2020 Coordination & Research and Innovation Action
under Grant Agreement No 731345.</p>
<img src="https://project.ecraft2learn.eu/wp-content/uploads/2017/01/eCraft2Learn-Final0.1.png">

</body></html>