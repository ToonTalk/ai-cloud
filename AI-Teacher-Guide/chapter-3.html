<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Camera Input - AI Teacher's Guide</title>
<link href="ai-teacher-guide.css" rel="stylesheet">
<link rel="icon" type="image/png" href="images/eCraft2Learn-Favicon.png" />
</head>
<body>
<h2>A teacher's guide to helping students build AI apps and artefacts</h2>
<h3>Chapter 3 - Camera Input</h3>
<h4>Ken Kahn, University of Oxford</h4>
<h3>Browser compatibility</h3>
<p>This guide includes many interactive elements that currently only run well in the Chrome browser.</p>
<h3>Introduction</h3>
<p>A camera connected to a computer can report the colour of each pixel in an image and not much else.
A description of what is in front of the camera is returned when those pixels are sent to an image recogntion service.
There are many kinds of things an image description may contain.
With speech recogntion the description is what was spoken, how confident the system is, and possible alternatives.
With image recogntion there are many possible descriptions: descriptive tags, possible captions, dominant colours,
location of faces and parts of the face if there are any, and the presence of landmarks, well-known entities, and logos.
Text can also be recognised.</p>

<p>A challenge in providing student-friendly programming blocks for image recogntion is that
different AI cloud services report different descriptions in different ways.
We currently provide interfaces to image recogntion services provided by Google, Microsoft, and IBM.
A further challenge is how to provide simple interfaces for simple tasks while still supporting more sophisticated uses and projects.</p>

<p>In the last few years there has been tremendous progress in computer vision.
High performance systems for identifying objects, recognising faces, interpreting sketches, and using medical images to aid diagnosis.
Driverless cars rely heavily upon computer vision.</p>

<h4>A simple image recogntion block</h4>
<p>blah blah</p>

<div class="iframe-container" style="width: 800px; height: 210px;">
<iframe class="iframe-clipped"
        scrolling="no"
        src="https://toontalk.github.io/ai-cloud/snap//snap.html"
        project_path="https://toontalk.github.io/ai-cloud/AI-teacher-guide-projects/simple image block IBM.xml"> 
</iframe></div>



<h3>Where to get these blocks to use in projects</h3>
<p>All of these speech output blocks as well other AI blocks are available to use in <a href="https://snap.berkeley.edu/" target="_blank">Snap!</a> in
this <a href="https://snap.berkeley.edu/snapsource/snap.html#present:Username=toontalk&ProjectName=eCraft2Learn" target="_blank">Snap project</a>.
They can also be used together with blocks for controlling Arduinos by downloading and then importing
<a href="https://toontalk.github.io/ai-cloud/AI-Teacher-Guide/eCraft2Learn%20S4A.xml" download>this file</a>
into <a href="http://snap4arduino.rocks/" target="_blank">Snap4Arduino</a>.

<h3>Learn about machine learning</h3>
<p>The next chapter is planned to be about machine learning.</p>

<h3>Acknowledgements</h3>
This research was supported by the <a href="https://project.ecraft2learn.eu/" target="_blank">eCraft2Learn project</a>
funded by the European Union's Horizon 2020 Coordination & Research and Innovation Action
under Grant Agreement No 731345. <img src="https://project.ecraft2learn.eu/wp-content/uploads/2017/01/eCraft2Learn-Final0.1.png">

</body></html>